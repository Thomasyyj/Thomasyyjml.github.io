# 第一章：绪论



## 1.1 引言

## 1.2 基本术语

- 数据集：$D = \{x_1,x_2,\cdots,x_m\}$, 
- 样本空间：$x_i \in \chi$
- 分类：预测的是离散集
- 回归：预测的是连续集
- 监督学习：数据有标记信息（如回归，分类）
- 无监督学习：数据无标记信息（如聚类）
- 泛化能力（generalization）：学得模型适用于新样本的能力
- 通常的假设：数据满足iid分布(independent and identically distributed)。指数据服从同一个分布且互相独立

## 1.3 假设空间

- 假设空间即为所有假设的集合(hypothesis space)
- 我们可以把学习过程看作一个在所有假设空间中进行搜索的过程。如西瓜分类可以看成一个搜索树的问题。
- 通常会有很多假设符合数据，我们把符合训练集的假设集合称为版本空间(version space)

## 1.4 归纳偏好

- 机器学习算法在学习过程中对某种类型假设的偏好称为归纳偏好(inductive bias)。可以理解为：算法认定某种假设是对的会给模型正反馈，其他的给负反馈。
- Occam's razor: 我们普遍接受的假设原则是：若有多个假设与观察一致，则选择最简单的那个
- No free lunch theorem: 如果在这样的假设下：所有问题出现的概率相同，且相同重要，那么无论算法多聪明，所有算法的期望性能是一样的！
- 但是注意，很多时候我们只关心特定问题，因此在特定问题下最优解是可能存在的。No free lunch theorem 告诉我们脱离具体问题空谈算法选择毫无意义。

## 1.5 发展历程

- 略，回头有空补历史hhh

## 1.6 发展现状

- 数据挖掘领域：统计学主要通过机器学习对数据挖掘发挥影响（因为统计学的研究成果通常需要机器学习来形成有效算法），机器学习领域和数据库领域是数据挖掘的两大支撑。
- 搜索：‘要建立输入与输出的联系，内核必然需要机器学习技术’